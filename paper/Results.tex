\section{Results}

\subsection{Accuracy}
\begin{table*}[ht!]
    \centering
    \begin{tabular}{@{}l|lll@{}}
    \toprule
    Translator & Overall & Without Trailing Comma Tests & Without Trailing Comma and Multiple Print Statements Tests \\ \midrule
    2to3       & 0.69                         & 0.92                                      & 0.90                                                                             \\
    fix-print & 0.62                          & 0.83                                      & 1.00                                                                               \\ \bottomrule
    \end{tabular}
    \caption{Computational accuracy of 2to3 and fix-print.}
    \label{table:accuracies}
\end{table*}

Overall, the findings suggest that 2to3 outperforms fix-print in terms of computational accuracy, not supporting my original hypothesis that a formally verified Python 2 to 3 transpiler would be more accurate than 2to3, although the two translators proved fairly close in accuracy, as seen in Table \ref{table:accuracies}. However, when excluding tests with trailing commas, the accuracy of both translators increased, and when further excluding tests with multiple print statements, fix-print attains a higher accuracy than 2to3, supporting my original hypothesis. The rationale for both of these exclusions is as follows.

During testing, it was discovered that the version of Python 2 (the \verb|python2-bin| package in the Arch User Repository (AUR), a collection of software packages intended for users of the Arch Linux operating system, the platform used during testing) used in testing was bugged. Trailing commas at the end of print statements should result in a newline character --- a special character that tells the computer to move to a new line, similar in effect to hitting enter on a keyboard --- not being printed. The Python 2 documentation states that is the intended behavior, and therefore both 2to3 and fix-print attempt to replicate that when translating. However, the version of Python 2 used outputted a newline character even when a trailing comma was present, contrary to its documented behavior, thus rendering otherwise accurate translations from both translators inaccurate. A version of Python 2 obtained directly from the official Python website was also tested, however that version exhibited the same incorrect behavior as the version from the AUR, thus it was not used for data collection. Therefore, for more accurate results, the accuracy of both translators excluding tests with trailing commas was calculated as well.

Excluding the trailing comma tests, 2to3 was still more accurate than fix-print. However, there were two tests that were unique within the test suite, as they contained multiple print statements instead of the only a single one, as every other test did. As fix-print was only specified to translate single print statements, it naturally produced incorrect translations for these two tests. Excluding these two tests, fix-print attained a higher accuracy than 2to3, supporting my original hypothesis, due to the fact that 2to3 failed the \verb|test-idempotency-1| test where fix-print did not, as seen in Tables \ref{table:2to3-accuracy} and \ref{table:fix_print-accuracy}. In Python 2, \lstinline[language=Python, style=pythonstyle]|print ()| outputs \verb|()|, as the empty parenthesis represent an empty tuple, which is a special type of list in Python. To replicate this behavior, the correct Python 3 translation should be \lstinline[language=Python, style=pythonstyle]|print(())|, as Python 3 print statements require an extra pair of parentheses around whatever content is to be outputted. fix-print is specified to always do as such, however in this case 2to3 translated \lstinline[language=Python, style=pythonstyle]|print ()| as \lstinline[language=Python, style=pythonstyle]|print()|, which is incorrect as that translation simply prints nothing, as there is no content within the parentheses.

2to3's failure to translate the \verb|test-idempotency-1| test correctly is intentional, as translating with 2to3 is intended to be \textit{idempotent}, meaning that if Python 2 code is fed into 2to3, producing Python 3 code, then feeding that code back into 2to3 should result in no changes. This is important as it allows for consistency and reproducibility of translations. If 2to3 always surrounded the content to be printed in print statements as fix-print is specified to do, then it would not be idempotent as it would always add parentheses in print statements, even for Python 3 code it already translated. This is a clear example of how formal verification is not a panacea for all code issues. Formal verification that all content in print statements would be surrounded by parentheses did specify that all resulting translations would be correct. However it also made the translator nonidempotent, which is also a good quality to have, especially in situations in large codebases where some code may be translated and some may not be, and it is desired that translated code is not further modified. Thus, any formal verification of a program is only as good as its specification. If the specification is faulty or implies an undesirable effect (such as nonidempotency), then the verified program will contain such flaws despite being 'mathematically proven to be correct.' In real codebases, it is unlikely that \lstinline[language=Python, style=pythonstyle]|print ()| is ever used as it has no useful effect, and 2to3 translates virtually ever other print statement accurately, thus in real scenarios where a Python 2 to 3 translator is needed, 2to3's emphasis on idempotency at the cost of a few edge cases being inaccurately translated is likely preferable to fix-print's guaranteed correctness at the cost of changing already translated files in a codebase each time a new translation is run.

\subsection{Performance}
\pgfplotstableread[row sep=\\,col sep=&]{
    Test                                  & 2to3 Average Run Time (ms) & fix-print Average Run Time (ms) \\
    test-1                               & 273                        & 4.4                              \\
    test-2                               & 253.6                      & 3.6                              \\
    test-3                               & 262.2                      & 3.8                              \\
    test-4                               & 253.8                      & 3.6                              \\
    test-5                               & 268                        & 3.6                              \\
    test-prefix-preservation            & 267.8                      & 4                                \\
    test-trailing-comma-1              & 289.8                      & 4.6                              \\
    test-trailing-comma-2              & 270.6                      & 3.8                              \\
    test-trailing-comma-3              & 279.8                      & 4.4                              \\
    test-tuple                           & 260                        & 4                                \\
    test-idempotency-1                  & 273.8                      & 4.4                              \\
    test-idempotency-2                  & 281                        & 4.2                              \\
    test-vargs-without-trailing-comma & 296                        & 3.6                              \\
    test-with-trailing-comma           & 275.4                      & 3.6                              \\
    test-no-trailing-comma             & 290.2                      & 3.4                              \\
    test-spaces-before-file            & 290.4                      & 3.6                              \\
    }\mydata

\begin{figure*}[ht]
    \begin{tikzpicture}
        \begin{axis}[
                ybar,
                ylabel={Run Time (ms)},
                symbolic x coords={test-1, test-2, test-3, test-4, test-5, test-prefix-preservation, test-trailing-comma-1, test-trailing-comma-2, test-trailing-comma-3, test-tuple, test-idempotency-1, test-idempotency-2, test-vargs-without-trailing-comma, test-with-trailing-comma, test-no-trailing-comma, test-spaces-before-file},
                xtick=data,
                xticklabel style={
                    rotate=90
                }
            ]
            \addplot table[x=Test,y=2to3 Average Run Time (ms)]{\mydata};
            \addplot table[x=Test,y=fix-print Average Run Time (ms)]{\mydata};
            \legend{2to3 Average Run Time (ms), fix-print Average Run Time (ms)}
        \end{axis}
    \end{tikzpicture}
    \caption{Mean run times of both 2to3 and fix-print for each test.}
\end{figure*}


fix-print was faster than 2to3 at translation, with fix-print translating code around two orders of magnitude faster than 2to3. This supports the hypothesis that a formally verified transpiler would perform better than a non-formally verified compiler. However, it is of vital importance to reemphasize the fact that both transpilers are written in two different programming languages. 2to3 was written in Python, whereas fix-print is written in Coq, with code extracted to OCaml. Due to the fundamental nature of both languages, programs written in OCaml will nearly always be faster than similar programs written in Python, due to the fact that Python programs are relatively slow due to the nature of how the Python language executes programs compared to other languages. Thus, a conclusion that formal verification lead to a performance gain is unwarranted, since the languages that both transpilers were written in affected performance much more than whether formal verification was used or not. However, the data suggests that formal verification is not a significant drag on performance. This lends credibility to advocates of formal verification, as possible performance regressions that might come along with the adoption of formal verification seem to not occur.

\subsection{Feasibility}
Formal verification added a considerable time cost to the development of a transpiler compared to if formal verification was not used. Development of fix-print took around three weeks for only a single 2to3 fixer, of which there are 52 in total. A similar transpiler developed without formal verification would have taken at most half of that time in the researcher's estimation. For programmers more experienced in formal verification, formal verification of such a project would likely take a lesser proportion of time; one programmer who worked on a formaly verification project estimated that it took 10\% more effort than if it were done without formal verification \autocite{Woodcock}. Formal verification of a Python 2 to 3 transpiler is likely technically feasible, as shown in this project, and it did certainly show effectiveness in catching edge cases. However, unlike in the transportation or compiler fields, Python 2 to 3 translation is not very safety critical. Unlike compilers which translate human-readable source code to computer-readable but human-unreadable, Python 2 to 3 translations have human-readable inputs and outputs, resulting in comparatively easy human verification of translations compared with compiled code. Thus, a major impetus for formally verifying code translators -- verifying that code is translated perfectly correctly -- is significantly reduced for Python translations as human verification is comparatively feasible, reducing the need for formal verification. Thus, although a formally verified Python 2 to 3 transpiler is technically feasible, given the additional time investment versus the comparatively low benefit from formal verification, formal verification is likely not the overall best approach to create a Python 2 to 3 transpiler. That being said, even for this relatively trivial project, formal verification was able to fix an edge case, showing that it has great potential to be useful in other applications.